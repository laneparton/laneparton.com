{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model\n",
    "1. (Recap from previous lesson)\n",
    "   1. Regression vs Classification Models\n",
    "2. Terminology\n",
    "   1. Training Set - data used to train the model\n",
    "   2. Notation\n",
    "      1. x = \"input\" variable/\"feature\"\n",
    "      2. y = \"output\" variable/\"target\"\n",
    "      3. m = number of training examples\n",
    "      4. (x, y) = single training example\n",
    "      5. x^(i),y^(i) (i^th training example), i = index\n",
    "3. Training set -> features, targets will create a learning algorithm (function) -> \"y-hat\"\n",
    "4. feature -> model -> prediction\n",
    "5. y-hat is an estimate\n",
    "6. How to represent (f)? (suppose straight line)\n",
    "   1. f(x) = wx+b\n",
    "7. Linear regress with one variable - single feature x\n",
    "   1. Univariant linear regression\n",
    "8. Cost Function Formula\n",
    "   1. w,b = parameters (what you can adjust during training) = coefficients = weights\n",
    "   2. How do you find w,b such that y-hat i is close to y i for all xi, yi\n",
    "   3. y-hat - y = error\n",
    "      1. J(w,b) = 1/2m(sum(y-hat - y)^2) = squared error cost function\n",
    "   4. model = fw,b(x) = wx+b\n",
    "   5. parameters = w,b\n",
    "   6. cost function = J(w,b) = 1/2m(sum(fw,b(x^(i) - y^(i))^2))\n",
    "   7. goal = minimize j(w,b)\n",
    "   8. Simplified - set b = 0 so f(x) = wx\n",
    "   9. Goal of linear regression: choose w to minimize j(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
